import os
import uuid
import requests
from PIL import Image
from io import BytesIO
from pydub import AudioSegment
from moviepy.editor import ImageClip, AudioFileClip, concatenate_audioclips, concatenate_videoclips
import openai

openai.api_key = os.getenv("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")  # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥


# âœ… GPTë¡œ ì‹œ ì „ì²´ â†’ ì¤„ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
def generate_prompts_from_full_poem(poem: str) -> list:
    system_msg = (
        "You're a poetic image prompt designer for DALLÂ·E. Given a Korean poem, "
        "generate one image generation prompt per line. Use consistent tone, symbolic imagery, "
        "soft cinematic lighting, and minimalist digital art style."
    )
    user_msg = f"Here is the poem:\n\n{poem}\n\nReturn a numbered list of image prompts, one for each line."

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ],
            temperature=0.7
        )
        content = response['choices'][0]['message']['content'].strip()
        prompts = [line.split('.', 1)[-1].strip() for line in content.splitlines() if line.strip()]
        return prompts
    except Exception as e:
        print(f"âŒ GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return []


# âœ… DALLÂ·E ì´ë¯¸ì§€ ìƒì„±
def generate_image_with_dalle(prompt: str, size="1024x1024"):
    try:
        response = openai.Image.create(prompt=prompt, n=1, size=size)
        image_url = response['data'][0]['url']
        image_response = requests.get(image_url)
        return Image.open(BytesIO(image_response.content))
    except Exception as e:
        print(f"âŒ DALLÂ·E ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


# âœ… ìŠ¬ë¼ì´ë“œì‡¼ ìƒì„±ê¸°
def generate_slideshow_from_poem(poem: str, audio_paths: list, config) -> str:
    lines = [line.strip() for line in poem.strip().split('\n') if line.strip()]
    if len(lines) != len(audio_paths):
        raise ValueError("ì‹œ ì¤„ ìˆ˜ì™€ ì˜¤ë””ì˜¤ íŒŒì¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    print("ğŸ§  GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
    prompts = generate_prompts_from_full_poem(poem)
    if len(prompts) != len(lines):
        raise ValueError("GPTê°€ ë°˜í™˜í•œ í”„ë¡¬í”„íŠ¸ ìˆ˜ê°€ ì¤„ ìˆ˜ì™€ ë‹¤ë¦…ë‹ˆë‹¤.")

    image_folder = config['IMAGE_FOLDER']
    video_folder = config['VIDEO_FOLDER']
    clips, audio_clips = [], []

    for line, prompt, audio_path in zip(lines, prompts, audio_paths):
        print(f"\nğŸ–‹ï¸ '{line}' â†’ GPT í”„ë¡¬í”„íŠ¸: {prompt}")
        image = generate_image_with_dalle(prompt)
        if image is None:
            image_path = os.path.join(image_folder, "default.jpg")
        else:
            image_path = os.path.join(image_folder, f"{uuid.uuid4().hex[:8]}.png")
            image.save(image_path)

        audio = AudioSegment.from_file(audio_path)
        duration = audio.duration_seconds

        img_clip = ImageClip(image_path, duration=duration).fadein(0.5).fadeout(0.5)
        clips.append(img_clip)
        audio_clips.append(AudioFileClip(audio_path))

    final_audio = concatenate_audioclips(audio_clips)
    final_video = concatenate_videoclips(clips).set_audio(final_audio)

    output_path = os.path.join(video_folder, f"slideshow_{uuid.uuid4().hex[:8]}.mp4")
    final_video.write_videofile(output_path, codec="libx264", audio_codec="aac", fps=24)

    return output_path
